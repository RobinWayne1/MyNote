# 第十章 集群

当遇到单机内存,并发,流量等瓶颈时,可以采用集群架构方案达到负载均衡的问题.

### 一.数据分布

#### Ⅰ.数据分布理论

分布式缓存数据库要解决的问题是如何把整个数据集按照分区规则映射到多个节点，而下面三种Hash分区方法就是为了解决这个问题而出现的。

##### 1、结点取余分区

结点取余分区的原理就是==让每一个服务器节点负责一个桶==。在通过某个key查找value时，根据节点数量N使用公式：`hash(key)%N`就可以求出该key被映射到了哪个节点。

优点：

1. 算法简单

缺点：

1. 如果集群需要扩容或收缩，那么**整个集群内的数据都需要重新映射迁移**。
2. **而在扩容或收缩过程中整个缓存服务都是失效的，这就会致使后端服务器压力瞬间暴增**
3. ==这两个缺点只是对于数据库集群的分区,而如果是对于Nginx负载均衡,则会在扩容的时候会出现大量后台服务器本地缓存失效,导致访问极度缓慢==

##### 2、一致性Hash分区（一致性指扩容前后只影响一个节点，不影响全局）

在一致性Hash算法中，缓存服务器节点和数据变成了同一个维度的概念：**缓存服务器节点和数据都被看成为哈希环上的一个节点。**==而哈希环就相当于一个成环的桶数组，一个哈希环中有2³²个桶。==一致性hash算法也是取模运算，只是上面描述的取模算法是对服务器数量进行取模，而一致性hash是对2³²取模。

![](E:\Typora\MyNote\resources\redis\Hash环.png)

###### ①、服务器映射

服务器不再是负责一个桶中的数据，而是它也作为一个节点加入进了这个桶数组中。

![](E:\Typora\MyNote\resources\redis\服务器Hash环映射.png)



服务器以自己的IP地址为key，使用公式:`hash(IPAddr)&(2³²-1)`就能够计算出服务器自己在Hash环中所处的桶位置。

###### ②、数据映射

当要向缓存集群存放数据时，使用公式：`hash(key)&(2³²-1)`计算出key在Hash环中所处的桶位置。

![](E:\Typora\MyNote\resources\redis\数据映射.png)

然后以该数据所在的桶位置为起点，顺时针找到第一个大于等于该值的一个服务器节点，也就是服务器A，该条数据就要存放在节点A中。

![](E:\Typora\MyNote\resources\redis\数据映射2.png)

优点：

1. 在扩容节点D时，需要将一部分 桶位置在节点D后的服务器节点 的数据迁移到节点D中（也可以将在节点D前的节点数据迁移到节点D）。所以对比于结点取余算法，一致性Hash算法的扩容操作只影响哈希环中相邻的结点，也就是只会造成部分数据无法命中而不会整个缓存服务都失效。

缺点：

1. 在数据迁移过程中依然会有相邻服务器节点的数据无法命中

2. 服务器节点很有可能不均匀的分布在Hash环上，使得数据分布不均匀。如果数据较多的节点出现故障，将导致失效的数量也将达到最大值。这个问题可以用虚拟节点来解决，**“虚拟节点”是“实际节点”(实际的物理服务器)在hash环上的复制品，一个实际节点可以对应多个虚拟节点，也就是一个缓存节点将负责多个范围的数据。**

   ![](E:\Typora\MyNote\resources\redis\虚拟节点.png)

3. ==扩容时如果只增加一个节点，**那么该节点减少的只是相邻服务器的压力**，这将使得缓存集群数据和负载不均衡。所以在扩容或收缩时必须增加一倍或减去一半节点才能保证数据和负载均衡。==

##### 3、虚拟槽分区

<img src="E:\Typora\resources\redis\虚拟槽分区结构.png" style="zoom:67%;" />

虚拟槽分区与节点取余分区有些类似，但是不同的是虚拟槽分区是一个节点负责多个桶，桶中存放数据；而节点取余则是一个缓存节点负责一个桶，而**这就导致了节点和数据耦合，使得扩容时整个缓存服务都是失效的**。

在虚拟槽分区中定义了16384个桶（在这里称为槽），每一个缓存节点都负责一部分的槽。所有的数据都根据公式：`CRC16(key)&16383`来得出存放的槽以确定存放的节点。

优点：

1. 解耦数据和节点之间的关系，简化节点扩容和收缩难度。**扩容或收缩在进行数据迁移时都是以槽为单位进行迁移的，这意味着在迁移过程中只有正在迁移的那个槽的数据无法命中，其他如即将迁移的槽或已经迁移完毕的槽中的数据还是能继续使用**，比一致性Hash算法更进一步降低了数据迁移开销。
2. 每个节点槽的数量都由用户自己分配，**并且节点负责的槽可以不连续**,所以不会出现一致性Hash分区的不均匀分布。

#### 2.集群功能限制

* ==key批量操作支持有限,目前只支持具有相同slot值的key执行mget,mset操作,存在于多个节点上的slot的key则不支持,**存在于相同节点的不同slot也支持.解决办法只能使用hash_tag.**==

* key事务操作支持有限,理由同上
* 不支持多数据库空间
* **复制结构只支持一层,不支持嵌套树状复制结构**

### 二.集群搭建

有三个步骤：准备节点、节点握手和分配槽。

#### Ⅰ、准备节点

在原`redis.conf`中做如下配置

```properties
port 6379
#开启集群模式
cluster-enabled yes
#节点超时时间,单位毫秒(⭐很重要的参数)
cluster-node-timeout 15000
#集群内部配置文件
cluster-config-file "node-6379.conf"
#默认是yes，当出现某槽不可用时整个集群不可用。但是在集群中某节点宕机的时候，如果希望其他节点仍然可以使用，那么就将其设置为no，表示只有宕机结点负责的槽不可用，其他仍然照常服务
cluster-require-full-coverage no
```

至此就可以启动redis了：

1. 在启动时检查是否开启集群模式，若不是则以普通模式启动；若是则以集群模式启动
2. 检查是否存在`cluster-config-file`指定的配置文件,若存在则以该集群配置启动;若不存在则生成集群配置。

集群模式的Redis除了原有的配置文件之外又加了一份集群配置文件,**集群内节点信息发生变化,如添加节点,节点下线,故障转移等节点会自动保存集群状态到集群配置文件中**,Redis自动维护集群配置文件,不需要手动修改。

#### Ⅱ、节点握手

刚启动的集群模式下的节点此时并没有在集群中，这个时候就需要通过节点握手将新建的结点加入进集群中。**而节点握手就是指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程。**

节点握手流程：

1. 在连接了新节点的客户端中，执行命令`cluster meet X.X.X.X 6380`,这是6379节点将会在本地创建6380信息对象,并向6380节点发送meet消息.

2. 6380节点收到meet后,保存6379节点信息并回复pong消息

3. 之后两节点彼此定期通过ping/pong消息进行正常的节点通信

只需要在任意节点上执行`cluster meet`命令加入新节点,==握手状态会通过消息在集群内传播,其他节点会自动发现新节点并发起握手流程.==

#### ⭐Ⅲ、添加从节点

作为一个完整的集群，每个负责处理槽的结点应该具有从节点，保证当他出现故障时可以自动进行故障转移。集群模式下，==Redis节点角色分为主节点和从节点，即不存在从节点也是主节点这样的拓扑结构==。**从节点负责赋值主节点槽信息和相关的数据，其复制流程和普通的主从复制流程相同。**

在要变成从节点的结点使用`cluster replicate 节点ID`就可以作为从节点了.

#### **Ⅳ、分配槽**

集群的节点拓扑已经建立完成,接下来就要向各节点分配槽。

可通过`redis-cli -h 127.0.0.1 -p 6379 cluster addslots {0..5461}`来分配槽。当16384个槽都全部分配完毕后，集群就正式开始运作。

### 三、节点通信

#### Ⅰ、通信类型

* meet消息：用于通知新节点加入，当meet消息完成后节点将正式加入进集群。
* ping消息：集群内每个节点每秒向其他多个节点发送ping消息已检测节点在线与交换彼此状态信息。
* pong消息：接收到meet或ping消息后，作为响应消息回复给发送方确认消息正常通信。
* fail消息：当节点判定集群内另一节点客观下线时，会向集群内广播一个fail消息通知集群内其他节点目标结点客观下线，得到fail消息的目标结点从节点将开始故障转移。

#### Ⅱ、通信流程

==**在分布式存储中需要提供维护节点元数据信息的机制,元数据是指:节点负责哪些数据,是否出现故障等状态信息.**==Redis集群采用P2P的Gossip协议,节点彼此不断通信交换信息,一段时间后所有节点都会知道集群完整的信息.

通信过程:

1. 集群中每个节点会开辟一个TCP通道用于节点之间通信

2. 每个节点在固定周期内通过特定规则选择几个节点发送ping消息.

   特定规则:

   * 每个节点维护定时任务默认每秒执行10次,每秒会随机选取5个节点找出最久没有通信的节点发送ping消息.
   * 每 100毫秒都会扫描本地节点列表,**如果发现节点最近一次pong消息的时间大于`cluster_node_timeout/2`,则立刻发送ping消息,防止该节点信息太长时间未更新。==如果服务器带宽资源紧张时，可以适当调大这个参数以防频繁发送ping，但这同时影响故障转移的发现速度。==**

3. 接收到ping消息的节点用pong消息作响应

**解析消息:**

**消息头存放的是自身节点的数据,==消息体存放的是集群内其他节点的数据==(至少3个,大约为1/10其他节点信息)**

* **解析消息头:消息头包含了发送节点的信息,如果发送节点==是新节点且消息时meet类型==,将节点信息加入到本地节点列表;如果为已知节点,则更新发送节点的状态,如槽映射关系,主从角色等状态**
* **解析消息体:如果消息体的`clusterMsgDataGossip`数组包含的节点时新节点,则尝试发起与新节点的meet握手流程;如果是已知节点,则根据`clusterMsgDataGossip`中的flags字段判断该节点是否下线,用于故障转移**

### 四、集群伸缩

#### Ⅰ、扩容流程

扩容有三个步骤：准备新节点、将新节点加入集群、**若该节点作为主节点，则迁移槽和数据**。

##### 1、准备新节点

与上面所说的集群建立一致

##### 2、将新节点加入集群

使用`cluster meet`命令将节点加入集群

##### 3、迁移槽和数据

<img src="E:\Typora\MyNote\resources\redis\槽迁移计划.png" style="zoom:50%;" />

1. 对目标结点发送`cluster setslot {slot} importing {sourceNodeId}`命令,通知目标节点准备导入槽slot

2. 对源节点发送`cluster setslot {slot} migrating {targetNodeId}`,通知源节点准备导出槽slot

3. ==源节点获取槽slot下count数量的键==,通过`cluster getkeyssinslot {slot} {count}`命令

4. ==通过`migrate {targetIP} {targetPort} keys`命令使用**流水线机制批量迁移**count数量键的数据==

5. 循环执行3、4两步，直到该槽中的数据全部迁移完成

6. 向集群内所有**主节点**发送`cluster setslot {slot} node {targetNodeId}`命令通知槽迁移的信息，让他们更新节点信息

#### Ⅱ、收缩流程

收缩有两个步骤:如果要取消的节点是主节点,将负责的槽迁移到其他节点、忘记节点

##### 1、下线迁移槽

使用`# redis-trib.rb reshard X.X.X.X port`,将该节点的槽迁移一部分出去.

##### 2、忘记节点

对集群中的其他节点发送`cluster forget {downNodeId} `,使得集群中的节点不在与该节点进行Gossip。至此，该节点正式下线。

### ==⭐五.请求路由==

**注:**

* ==Lua和事务需要操作的key必须在一个节点上，如果要使用这两个功能只能使用hash_tag来保证数据在同一个节点==

* **使用`set {hash_tags}:tweet:1`,可以使相同的hash_tag具备相同的slot**

#### Ⅰ、请求重定向(MOVE重定向)

**在集群模式下,Redis节点接收任何键相关命令时==首先根据CRC16函数计算key对应的槽==,再根据Gossip通信维护的节点槽信息找出所对应的结点,如果结点是自身,才处理命令;==否则则要返回MOVE重定向错误以告诉客户端该key对应的槽在哪个节点==**

#### ==⭐Ⅱ、Smart客户端==

Smart客户端通过在内部维护`slot-->node`的映射关系,在**==客户端本地就可以实现键到节点的查找==**,从而保证IO效率最大化(使用`cluster slots`或`cluster nodes`命令来获取槽和节点的映射关系)

==**流程如下:(注意两种错误:连接错误和MOVE重定向错误)**==

1. **计算hash并根据slots缓存映射获取目标节点连接,发送命令**

2. **如果出现连接错误==(连接错误出现可能是因为集群节点宕机)==,则使用随机连接==(即连接随机集群节点,这样做的目的是使得节点报MOVE重定向错误以更新slot缓存,新节点可能是宕机节点的从节点)==重新执行键命令,并使 重试次数参数-1**

3. **捕获到MOVE重定向错误,发送`cluster slot`命令来更新缓存,之后则根据缓存继续进行重试**

4. **当重试次数到达0,抛出`JedisClusterMaxRedirectionsExcetion`异常**

#### Ⅲ、ASK重定向

Redis在进行==集群伸缩==的过程中,数据从源节点迁移到目标节点过程中,如果客户端根据本地缓存发送命令给源节点

* 如果此时键不存在,则**==可能存在于目标结点==**,这时原结点会返回客户端ASK重定向异常,然后客户端**向目标节点发送asking命令打开客户端连接标识,再执行键命令.如果存在数据则执行,不存在则返回不存在信息**
* 如果源节点存在数据则直接返回

==ASK重定向说明集群正在进行slot数据迁移,客户端无法知道什么时候迁移完成,因此只能是临时性的重定向,客户端不会更新slots缓存.但是MOVED重定向说明键对应的槽已经明确指定到新的节点,因此需要更新slots缓存==

##### 1、批量操作

正在迁移过程中进行mget操作,如果mget里面的key此时已经不在同一个节点上则会报错

但是使用Pipeline进行逐条get操作时,源节点会对每条get操作返回信息,如果数据在源节点则直接返回,如果已迁移则返回ASK重定向,可以根据重定向信息重新请求目标节点得到数据.所以集群环境下对于使用批量操作的场景,优先使用Pipeline方式。

### 六.故障转移

==**⭐故障转移的大体流程:**==

1. 集群中节点会定期向其他节点发送ping消息,**消息中带有本地节点的集群拓扑状态**,接收节点以pong回应,若集群中某节点在`cluster-node-timeout`内一直与另一集群节点通信失败,则更新此节点本地状态为客观下线
2. 下线节点的下线状态通过ping消息在集群中传播,当集群中的 某**主**节点 发现有半数以上的其他节点的ping消息的下线节点状态都为主观下线,则标记此下线节点状态为客观下线,此时该节点将向整个集群广播下线节点的fail消息
3. 当**下线节点的从节点(从节点全权负责故障转移)**接收到fail消息后,开始准备故障恢复.故障恢复过程将通过集群中各个主节点的投票选举选出替换的从节点,从节点将会替换成主节点

故障发现通过消息传播机制实现的,包括主观下线和客观下线

#### Ⅰ、主观下线

##### 1、主观下线流程

1. 节点a发送ping消息给节点b,如果通信正常将接受到pong消息,节点a更新最近一次与节点b的通信时间

2. 如果节点a与节点b通信出现问题则断开连接,下次会进行重连.如果通信一直失败,则节点a记录的与节点b最后通信时间将无法更新

3. a节点的cron定时任务检测到与节点b最后通信时间超过`cluster-node-timeout`时,更新本地对节点 为主观下线（即pfail状态）
4. 之后节点a在与其他集群内节点进行ping/pong通信时就会捎带上对节点b的主观下线判断

#### Ⅱ、客观下线

##### 1、触发条件

当某个节点判断另一个节点主观下线后,相应的节点状态会跟随消息在集群内传播.当节点在ping/pong消息体中发现含有主观下线的节点状态时,会在下线报告链表结构中记录某节点对目标结点的下线报告。当在下线报告链表中发现==半数以上====持有槽==的主节点都标记某个节点是主观下线时,触发客观下线流程

必须是持有槽的节点原因:集群模式下只有处理槽的主节点才负责读写请求和集群槽等关键信息的维护,**而从节点只进行主节点数据的状态信息的复制**。

##### 2、客观下线流程

1. 当消息体内含有其他节点的pfail状态会判断发送节点是否是主节点,如果发送的节点是主节点则对报告的pfail状态处理

2. 将某节点对目标结点的下线报告记录到clusterNode内部下线报告链表中
   * 每个下线报告都会存在有效期,每次在尝试触发客观下线时都会检测下线报告是否过期(期限:cluster_node_timeout*2),对于过期的下线报告将被删除,**即如果主观下线上报速度赶不上下线报告过期速度,那么故障节点永远无法标记为客观下线**

3. 根据更新后的下线报告链表尝试客观下线
   * 若下线报告大于槽主节点数量一半,**标记故障节点客观下线并广播fail消息通知所有节点将故障节点标记为客观下线**

####  ==Ⅲ、故障恢复==

当从节点收到广播的fail消息时,将会触发故障恢复流程

1. 资格检查

   如果从节点与主节点断线时间超过`cluster-node-time*cluster-slave-validity-factor`则从节点不具备故障转移资格

2. 准备选举时间

   当从节点符合故障转移资格后,更新 `触发故障选举的时间`,**只有到达该时间才能执行后续流程**。复制偏移量越大的节点说明从节点延迟越低,则更新的 `触发故障选举的时间`将越接近当前时间。目的是通过延迟选举机制支持节点优先级。

3. 发起选举
   1. 更新配置纪元，每一次选举都会使配置纪元数值递增以记录选举事件
   2. 广播选举消息,**并记录已发送过消息的状态,保证该从节点在一个配置纪元内只能发起一次选举**

4. 选举投票

   只有持有槽的主节点才会处理故障选举消息,每个持有槽的节点在一个配置纪元内都有唯一的一张票,==**当接到第一个请求投票的从节点消息时就投给他,之后相同配置纪元内其他从节点的选举消息将忽略,这就控制了延迟越低的从节点越有机会晋升为主节点**==。

   其中每隔配置纪元代表一次选举周期,如果在开始投票后的`cluster-node-timeout*2`时间内从节点没有获取足够数量的投票,则本次选举作废.从节点对配置纪元自增并发起下一轮投票直到成功。

5. 替换从节点

   当从节点收到`主节点数(报错故障节点)/2+1`个票数时则进行替换主节点操作。

   1. 当前从节点取消复制变为主节点，并使其他从节点复制新的主节点
   2. 撤销故障主节点的槽并委派给自己
   3. 向集群广播pong消息,通知集群内所有节点当前结点的主从状态和槽映射信息

### ==⭐七、集群运维==

#### Ⅰ、集群读写分离

##### 1、只读连接

**集群模式下的从节点默认不接受任何读写请求，发送过来的键命令会重定向到负责槽的主节点上。**当需要从节点分担主节点读压力时，可以在客户端中在每次新建连接时都向从节点发送`readonly`命令以开启从节点的读操作**(此命令是连接级别生效,==而主从复制配置的`slave-read-only`在集群模式下是无效的==)**,之后 该连接的从节点 就可以响应其主节点对应槽的读操作

##### 2、读写分离

Smart客户端不支持集群的读写分离,所以==读命令的从节点路由==必须自己实现。

要解决读命令的从节点路由，就**就只能在客户端里维护主节点到从节点的映射，通过MOVE重定向错误找到key的目标主节点==（MOVE重定向返回的信息都是主节点信息）==，从而向它的从节点发请求**。

总而言之，要造大量轮子，不如不用读写分离。