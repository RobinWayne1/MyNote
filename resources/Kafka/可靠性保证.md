# 可靠性探究

## 一、重要参数

### Ⅰ、`acks`

此参数是Kafka生产者中最重要的参数。**此参数用来决定某消息发往的分区中，需要有多少个此分区的副本接收到此消息才返回一个成功响应给生产者。**

三种类型：

1. `acks=1，默认值`

   消息首先发往leader分区，当leader分区接收到消息后即返回成功响应给生产者。这种方式可以保证若此时leader分区副本在进行故障转移，生产者可以得知这种异常并可以进行重试以保证消息不丢失。而这种方式导致的问题就是：leader分区副本收到消息，此时follower分区副本还没来得及发`FetchRequest`给leader副本拉消息leader副本就宕机了。此时必然进行leader选举，选举成leader的follower中没有此消息，而生产者也已收到成功响应不会重试，此时消息丢失。

2. `ack=0`

   生产者在消息发出后不需要等待Kafka的任何响应。如果在消息传输途中丢失，那么消息就丢失了。

3. `ack=-1`

   生产者发送消息后，Kafka需要等待ISR中所有副本都成功写入消息后，才返回成功响应，这就是最强可靠性。**然而如果此时ISR中只有leader副本，那么就退化成了acks=1的情况**。对于这种情况还有一个联动参数`min.insync.replicas`,这个参数制定了ISR集合中最小副本数。若ISR小于此配置，那么就会抛出异常。

### Ⅱ、`retries`和`retry.backoff.ms`

在遇到一些异常如leader副本正在选举、网络抖动导致`NetWorkException`等,生产者在接收到这些异常时会在异步线程中进行重试。

`retries`就是用来指定重试的次数，而`retry.backoff.ms`则是指定每次重试之间的间隔。**主要是用于防止无用的重试，如选举未完成但都已经重试完了，那重试来还有什么意义呢？**

### Ⅲ、`max.in.flight.requests.per.conniction`

这个参数作用于某些需要用Kafka来实现严格顺序消费的场景。此参数的含义是生产者收到服务器响应前可以发送多少消息，将该参数设置为1就会使得`KafkaProducer`的消息发送完完全全线性执行(有锁的情况下只是单线程发送,==再加上这个就是重试的时候也是线性的了==)。**若不设置该参数，消息1发送不成功进行重试,此时消息2发送成功,之后消息1重试成功,那么这两个消息在Kafka中的顺序就颠倒了。**

### Ⅳ、`replica.lag.time.max.ms`

含义:**==若当前follower副本上一次 完整同步完leader副本的时间 距当前时间的差值==**超过该参数,则将次follower副本移到OSR副本中

## 二、ISR伸缩机制

### Ⅰ、ISR收缩

副本有两种情况导致失效：

1. 副本所在broker宕机
2. 副本同步消息过于落后

Kafka的监测机制:当follower副本将leader副本**LEO之前的日志全部同步**,则会刷新一次`lastCaughtUpTimeMs`标识。除此之外Kafka还会启动一个定时任务叫做`isr-expiration`，这个定时任务定时检查当前时间与副本`lasCaughtUpTimeMs`的差值是否超过上面所说的`replica.lag.time.max.ms`，若是就将follower移到OSR。

### Ⅱ、ISR扩充

当一个follower分区副本在OSR时，判定该follower是否有资格进入ISR的条件是：此副本的LEO是否**==不小于leader副本的HW（注意是与leader副本的HW比较而不是LEO比较）==**。有一点需要注意，就是HW是会随着follower进出ISR而改变的，如果某follower离开ISR，那么HW的计算也将忽略掉该follower。

### 三、日志读取机制

（类似于主从复制机制啦,日志读取不过就是follower结点读取leader副本结点的日志,并更新follower结点的本地日志）

1. 生产者客户端发送消息至leader分区副本

2. leader分区副本将消息持久化追加到本地日志中，并更新LEO值

3. follower副本发送`FetchRequest`,向leader副本请求同步数据,**同时携带上自己的LEO**(其中灰色为leader副本,白色为follower副本)

   <img src="E:\Typora\MyNote\resources\Kafka\日志同步机制1.png" style="zoom:130%;" />

4. leader副本收到`FetchRequest`。首先，leader将检查各个follower的request的LEO，**==用他们的LEO与自己的LEO相比较取其中的较小值更新自己的HW，并更新leader副本本地记录的各follower结点的LEO值。（说实话并不是很理解为什么还要与自己的LEO比较，难道follower的LEO还会大于leader的LEO吗？）==**然后从本地日志中**读取以LEO为起始的日志并带上自己的HW**返回给follower。（读取的日志量并不确定）

   <img src="E:\Typora\MyNote\resources\Kafka\日志同步机制2.png" style="zoom:130%;" />

5. follower副本接收到`FetchResponse`。首先，follower取出response的HW，==**将这个HW与自身的LEO进行比较取其中的较小值更新自己的HW(这个倒是没有疑问,因为leader的HW会比follower的大或者是小都有可能,如新的的follower加进来了,那么leaderHW就比某follower小;如果是正常逻辑,那leader的HW就会比follower的大)。**==然后将收到的消息追加到本地日志中，更新LEO值。

### 四、Leader Epoch

#### Ⅰ、同步错误的两种场景

##### 1、数据丢失

集群中有两个角色followerA和leaderB，followerA起始状态→`LEO为1，HW也为1`；leaderB起始状态→`LEO为2，HW也为1`。followerA请求同步日志，leaderB将id=2的数据返回给followerB。此时状态：followerA→`LEO为2，HW为1`；leaderB→`LEO为2，HW为2`。

若此时followerA宕机重启，Kafka将会自行==做一个日志截断,**①就是根据磁盘中的HW位置,直接删除掉HW之后的日志**。==

> **在follower重启后会做两件事：日志截断与向leader副本发送`FetchRequest`**

若之后leaderB宕机重启，followerA成为leaderA，leaderB成为followerB。此时followerB还会==做一个日志截断，**⭐⭐②由于follower副本HW不能比leader副本HW高，所以将根据leader副本的HW删除之后的日志。**==

至此，id=2的消息消失。

> 为什么需要日志截断？
>
> 若没有日志截断，当leader宕机一段时间之后又作为follower重新加入Kafka集群，此时原leader的消息将会与原follower的消息严重不一致。具体可看https://blog.csdn.net/weixin_41947378/article/details/108619757。日志截断是一步必要的操作。（按照博客所述，如果开启日志截断并将ack置为-1，那么将没有producer消息丢失的问题，因为follower并没有收到消息，此时生产者并不认为消息送达。以生产者的角度来说日志截断 只是截断他认为 没有送达的消息而已，语义正确）

有什么办法解决数据丢失呢？可以在宕机重启后不以本地磁盘的HW为准，而是**在接收到leader的`FetchResponse`并更新HW后,再进行日志截断**。这样的话再上述followerA宕机重启时将不会发生日志截断了。

##### 2、数据不一致

然而无论使用不使用这种解决方案都不能解决日志不一致的问题。

同样是followerA和leaderB，followerA起始状态→`LEO为1，HW也为1，包含id为1的消息`；leaderB起始状态→`LEO为2，HW为2，包含id为1、2的消息`。此时双方同时宕机**（注意followerA此时没有id=2的消息）**,A先恢复过来,此时A变成leaderA，之后leaderA收到一条id=3的消息，此时leaderA状态→`LEO为2，HW为2，包含id为1、3的消息`。B恢复，成为followerB，（解决方案的流程：马上向leader发送`FetchRequest`,leader响应HW=2的`FetchResponse`后更新HW*（原本HW就是2）*），然后进行日志截断发现HW与LEO相同，不需要进行日志截断，随即继续运行。

此时leaderA没有id=2的消息，而followerB则没有id=3的消息，而他们的offset都是2，这就造成了数据不一致。

#### Ⅱ、解决方案

##### 1、基本概念

LeaderEpoch机制有两个变量。

1. `leader epoch`。`leader epoch`存在于每个副本中，用来标识本broker基于**==哪一代leader==**在运行。如果leader宕机发生故障转移，那么此时每一个运行中副本的`leader epoch`都会+1。
2. `LeaderEpoch->StartOffset矢量`。这个矢量同样存在于每个副本中（其实不如说是不同纪元的SO映射），**用来标识某纪元下副本写入的第一条消息的offset。**

##### 2、⭐⭐作用机制

broker宕机重启后，将第一时间向此时的leader发送`OffsetsForLeaderEpochRequest`，**==请求中包含副本的`leader epoch`。接收到请求的leader将检查`leader epoch`值，若和此时leader的`leader epoch`相同，则直接将LEO作为response返回给follower（因为和当前leader相同，所以不可能需要截断，直接返回LEO就是为了避免截断）；若和此时leader的`leader epoch`不相同，那么leader就查找`leader epoch+1->StartOffset映射`获取follower的纪元所对应的SO返回给follower。（这里返回SO的原因就是要删除follower在旧纪元拿到的，而在当前leader没有的数据，通过这来解决不一致性）此时follower将根据leader返回的SO，截断包括SO之后的offset的消息。==**

#####  3、两种场景的解决过程

###### 1、数据丢失

集群中有两个角色followerA和leaderB，followerA起始状态→`LEO为1，HW也为1`；leaderB起始状态→`LEO为2，HW也为1`。followerA请求同步日志，leaderB将id=2的数据返回给followerB。此时状态：followerA→`LEO为2，HW为1`；leaderB→`LEO为2，HW为2`。

若此时followerA宕机重启，**将首先发送`OFLER`请求给leader,leader发现请求中的`leader epoch`与leader的相同,直接将LEO值作为SO返回给followerA。followerA发现返回的SO要等于==（要与之前的场景保持一致，所以是等于不是大于）==当前分区的offset，所以不会进行日志截断。**

若之后leaderB宕机重启，followerA成为leaderA，leaderB成为followerB，**`leader epoch`将从LE0变成LE1。此时followerB同样向ledaerA发送`OFLER`请求，leaderA将会查找`LE0->0`矢量,得到SO=0返回给followerB。followerB截断日志（所有日志清空了），开始从头同步日志，至此日志并不会丢失。**

###### 2、数据不一致

followerA起始状态→`LEO为1，HW也为1，包含id为1的消息`；leaderB起始状态→`LEO为2，HW为2，包含id为1、2的消息`。此时双方同时宕机**（注意followerA此时没有id=2的消息）**,A先恢复过来,此时A变成leaderA，之后leaderA收到一条id=3的消息，此时leaderA状态→`LEO为2，HW为2，LE1->2,包含id为1、3的消息`。

B恢复变成followerB,**首先发送`OFLER`请求给leaderA,leaderA随即查找`LE0->0映射`,返回SO=0的响应给followerB。随后followerB进行日志截断==（所有日志清空，也就是丢了id=2的消息，这就要设置ack=-1来保证不丢id=2的消息了）==**，然后重新同步leaderA的日志，至此leaderA和followerB的消息保持一致

### 五、不采用读写分离的原因

1. 采用读写分离也就是说主写从读，那么leader写入数据后同步到follower肯定会有一定的时间，那么在这段时间中就会造成主从数据不一致问题。
2. 其次不同于redis，对于leader消息（日志）的读取和follower消息（日志）的存储必须经过磁盘，而redis则可以选择不经过磁盘完全基于内存的存储。所以主从复制的效率相较于redis是低得多的，这种特性将进一步扩大主从数据不一致和延时的问题。

