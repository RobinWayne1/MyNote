# 消费者

## 一、消费者与消费者组

### Ⅰ、P2P与PUB/SUB

一般而言,mq都有两种**==消息投递模式:点对点模式和发布订阅模式。==**点对点模式就是将mq作为一个纯粹的队列，生产者将消息插入主题中，消费组中的消费者获取并删除主题分区中的消息并进行消费；而发布订阅模式就是生产者将消息插入kafka的某主题中， 消费者组中的消费者订阅该主题，多个订阅该主题的 消费者组中的消费者将都能获取到该消息。

### Ⅱ、基础概念

上面所说的原理就是一条消息能够被多个消费者组消费，那么消息是如何在消费者组内流动的呢？在默认策略下，消费者组中 **订阅了某主题的消费者** 能够==平均负责该主题下的所有分区==，如下图所示。==**也就是说对于消费者组内而言，一个分区中的消息只会被一个消费者消费**。==（简单来说=某主题下的分区：某消费者组中的消费者=n:1）

![](E:\Typora\MyNote\resources\Kafka\消费者与消费者组与分区的对应关系.png)



消费者与消费者组的概念使得消息消费具有伸缩性，我们可以通过增加消费者组中的消费者个数来提升整体的消费能力。然而如果订阅了某主题的 消费者组中的消费者个数大于该主题的分区数，那么将会有部分消费者分配不到分区消费。

> 这里提一嘴以**==添加分区个数和消费者个数来提升整体性能的方案==**，这两者个数的协同增加能够带来吞吐量提升(当然只增加分区个数也能带来提升，不过就是对于Kafka服务端的提升)，但是前提是新增的分区能够很好的部署在各个不同的broker上（当然多加一个分区就多一个broker那就最爽了）。然而由于要考虑Kafka高可用的问题，那么每增加一个分区将要增加几个follower副本来保证高可用，这样带来的机器消耗将是倍数级增长。
>
> 其次就是文件句柄的问题，对于每个分区都会对应两个文件：索引文件和日志文件，如果某机器中的分区越多，其占用的文件描述符也就越多，非常容易超过最大fd上限。

## 二、客户端开发

一个正常的消费逻辑步骤：

1. 配置消费者客户端参数，创建客户端实例。

   ```java
   Properties props =initConfig() ;
   KafkaConsumer<String , String> consumer= new KafkaConsumer<>(props) ; 
   ```

2. 订阅主题

   ```java
   consumer.subscribe(Arrays.asList(topic)) ; 
   ```

3. **拉取消息并消费**

   ```java
        try {
            	//循环拉取
               while (isRunning.get()) {
                   //Kafka用拉模式
                   ConsumerRecords<String, String> records =
                           consumer.poll(Duration.valueOf("1000"));
                   for (ConsumerRecord<String, String> record : records) {
   					//消费逻辑
                   }
               }
           }
   ```

4. **提交消费位移**

   默认参数`poll()`自动提交消费位移,下面细嗦。

5. 关闭消费者实例

   ```java
   finally {
       consumer.close()
   }
   ```

### Ⅰ、客户端参数

总结一下比较重要的客户端参数：

1. `group.id`

   定义使用这个配置的`KafkaConsumer`属于哪个消费者组

2. `max.poll.records`

   指定一次`poll()`请求中从Kafka拉取的最大消息条数

3. `enable.auto.commit`

   配置是否开启自动提交消费位移功能,每次调用`poll()`代码将会检查是否进行位移提交

4. `auto.commit.interval.ms`

   表示每次自动提交消费位移的时间间隔,时间设置的太长容易出现重复消费的情况;设置的太短可能出现消息丢失的情况(如果是多线程消费就会出现,下面细嗦)

5. `partition.assignment.strategy`

   消费者分配分区的策略

### Ⅱ、订阅主题

#### 1、消费者组与主题分区

看消费者与消费者组的基础概念时可以留意到，我无时无刻不在强调是消费者订阅的主题而不是消费者组订阅的主题，消费者组只是一个逻辑的概念。只有某个消费者组中的消费者订阅了主题，这个消费者组才会接收到该主题的消息。

#### 2、订阅方式

##### ①、`public void subscribe(Collection<String> topics)`与`public void subscribe(Pattern pattern)`

消费者订阅主题。第一个方法提供订阅的主题名称集合，第二个方法就是直接通过主题名称的正则去订阅主题。==要注意一个地方就是一个消费者可以订阅多个主题，换句话来说不只是 主题下的分区：消费组中的消费者=n：1，而主题：消费组中的消费者也是=n：1。此时消费者线程就可以根据拉取到的不同主题的消息进行不同的逻辑处理。==

##### ②、`public void assign(Collection<TopicPartition> partitions)`

消费者可以直接订阅特定主题的特定分区,==此举将跳开`partition.assignment.strategy`的限制,分区与消费者的对应关系不具备自动再均衡功能（也就是消费者的增加减少，分区的负责消费者也将发生变化）==

三种不同的订阅方式代表着三种互斥的订阅状态，每一个`KafkaConsumer`只能够选择其中一种方法进行订阅,如果同时使用将会抛出异常。

### ==Ⅲ、拉取消息消费==

==**MQ的消息消费模式有两种：推模式和拉模式。推模式指服务端主动将消息推送给消费者，这种模式的实时性比较好，但是客户端消费者有可能被源源不断到达的消息压垮；而拉模式的实时性较差，但是客户端可以根据自身的处理能力控制拉取信息量。**而Kafka采用的是拉模式。==

```java
public ConsumerRecords<K, V> poll(long timeout)
```

`poll()`将会拉取该消费者订阅的主题中负责的分区的消息,`ConsumerRecords`对象中专门有一个成员变量`Map<TopicPartition, List<ConsumerRecord<K, V>>>`来区分某条消息属于哪个主题分区。其中timeout指拉取时的阻塞时间，在拉取时没有可用数据会发生阻塞。

#### 1、分区维度消费

```java
public List<ConsumerRecord<K, V>> records(TopicPartition partition) 
```

由上面所说的成员变量就可以知道有这种方法，传入partition就返回该分区相应的消息。

#### 2、主题维度消费

```java
public Iterable<ConsumerRecord<K, V>> records(String topic)
```

### Ⅳ、位移提交

#### 1、背景

在每次调用`poll()`方法时,其返回的是分区中没有被消费过的消息集。要做到这一点，Kafka服务端就必须维护==每一个消费者组已经消费过的**主题分区的**消息的位移==（因为对于消费者组来说，某一个主题分区中的消息该消费者组只会消费一次，注意这个维度）。当发生再均衡操作时，例如新增了消费者，这个新来的消费者无从得知所属的消费者组已经消费了其负责的分区多少消息，所以这个时候只能根据Kafka服务端持久化保存的 **消费者组+主题分区唯一标识的消费位移**来获取未被消费的消息集。

#### 2、存储机制

Kafka将消费者提交的消费位移存储到一个内部的主题`_consumer_offsets`中。（旧版客户端是存储在ZK里的,可以看出Kafka在极力摆脱ZK,听说新版本已经完全摆脱ZK了）

![](E:\Typora\MyNote\resources\Kafka\位移提交下标.png)

消费者每次提交的消费位移都是`position`而不是`lastConsumerOffset`。

#### 3、三种提交方式

首先讲讲位移提交的原理,稍微看了下消费者客户端源码。

每次调用`poll()`方法拉取消息之后,内部会将拉取到的最新消息offset+1放入一个叫做`TopicPartitionState`对象的`position`成员变量中。在进行位移提交时,将会直接以该对象的`position`,也就是如上图所显示的那样,提交消费位移。因此可以看出，Kafka的消费位移提交是一种值覆盖的形式，而不是增量形式。有了这种覆盖的实现方法，`seek()`的操作也变得简单至极,直接改变`TopicPartitionState`的`position`就完事了,之后进行位移提交再拉取消息时,由于位移提交的位移受到`seek()`的影响回溯了,那么拉取的消息也就回溯了。==(这里真的要实验一下)==

##### ①、`commitSync()`

`commitSync()`即是同步提交,该方法将会==**根据`poll()`方法拉取消息的最大位移进行提交**==,只要没发生不可恢复错误,该方法就会一直阻塞消费者知道直到完成。而如果出现了不可恢复错误，也可捕获进行相应的处理。`KafkaConsumer`是一个线程不安全的对象,虽然其每个方法

三种提交的优缺点

### Ⅴ、客户端实例

