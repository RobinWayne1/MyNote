# 消费者

## 一、消费者与消费者组

### Ⅰ、P2P与PUB/SUB

一般而言,mq都有两种**==消息投递模式:点对点模式和发布订阅模式。==**点对点模式就是将mq作为一个纯粹的队列，生产者将消息插入主题中，消费组中的消费者获取并删除主题分区中的消息并进行消费；而发布订阅模式就是生产者将消息插入kafka的某主题中， 消费者组中的消费者订阅该主题，多个订阅该主题的 消费者组中的消费者将都能获取到该消息。

### Ⅱ、基础概念

上面所说的原理就是一条消息能够被多个消费者组消费，那么消息是如何在消费者组内流动的呢？在默认策略下，消费者组中 **订阅了某主题的消费者** 能够==平均负责该主题下的所有分区==，如下图所示。==**也就是说对于消费者组内而言，一个分区中的消息只会被一个消费者消费**。==（简单来说=某主题下的分区：某消费者组中的消费者=n:1）

![](E:\Typora\MyNote\resources\Kafka\消费者与消费者组与分区的对应关系.png)



消费者与消费者组的概念使得消息消费具有伸缩性，我们可以通过增加消费者组中的消费者个数来提升整体的消费能力。然而如果订阅了某主题的 消费者组中的消费者个数大于该主题的分区数，那么将会有部分消费者分配不到分区消费。

> 这里提一嘴以**==添加分区个数和消费者个数来提升整体性能的方案==**，这两者个数的协同增加能够带来吞吐量提升(当然只增加分区个数也能带来提升，不过就是对于Kafka服务端的提升)，但是前提是新增的分区能够很好的部署在各个不同的broker上（当然多加一个分区就多一个broker那就最爽了）。然而由于要考虑Kafka高可用的问题，那么每增加一个分区将要增加几个follower副本来保证高可用，这样带来的机器消耗将是倍数级增长。
>
> 其次就是文件句柄的问题，对于每个分区都会对应两个文件：索引文件和日志文件，如果某机器中的分区越多，其占用的文件描述符也就越多，非常容易超过最大fd上限。

## 二、客户端开发

一个正常的消费逻辑步骤：

1. 配置消费者客户端参数，创建客户端实例。

   ```java
   Properties props =initConfig() ;
   KafkaConsumer<String , String> consumer= new KafkaConsumer<>(props) ; 
   ```

2. 订阅主题

   ```java
   consumer.subscribe(Arrays.asList(topic)) ; 
   ```

3. **拉取消息并消费**

   ```java
        try {
            	//循环拉取
               while (isRunning.get()) {
                   //Kafka用拉模式
                   ConsumerRecords<String, String> records =
                           consumer.poll(Duration.valueOf("1000"));
                   for (ConsumerRecord<String, String> record : records) {
   					//消费逻辑
                   }
               }
           }
   ```

4. **提交消费位移**

   默认参数`poll()`自动提交消费位移,下面细嗦。

5. 关闭消费者实例

   ```java
   finally {
       consumer.close()
   }
   ```

### Ⅰ、客户端参数

总结一下比较重要的客户端参数：

1. `group.id`

   定义使用这个配置的`KafkaConsumer`属于哪个消费者组

2. `max.poll.records`

   指定一次`poll()`请求中从Kafka拉取的最大消息条数

3. `enable.auto.commit`

   配置是否开启自动提交消费位移功能,每次调用`poll()`代码将会检查是否进行位移提交。只有设置成false，才可以在代码中手动提交。

4. `auto.commit.interval.ms`

   表示每次自动提交消费位移的时间间隔,时间设置的太长容易出现重复消费的情况;设置的太短可能出现消息丢失的情况(如果是多线程消费就会出现,下面细嗦)

5. `partition.assignment.strategy`

   消费者分配分区的策略

### Ⅱ、订阅主题

#### 1、消费者组与主题分区

看消费者与消费者组的基础概念时可以留意到，我无时无刻不在强调是消费者订阅的主题而不是消费者组订阅的主题，消费者组只是一个逻辑的概念。只有某个消费者组中的消费者订阅了主题，这个消费者组才会接收到该主题的消息。

#### 2、订阅方式

##### ①、`public void subscribe(Collection<String> topics)`与`public void subscribe(Pattern pattern)`

消费者订阅主题。第一个方法提供订阅的主题名称集合，第二个方法就是直接通过主题名称的正则去订阅主题。==要注意一个地方就是一个消费者可以订阅多个主题，换句话来说不只是 主题下的分区：消费组中的消费者=n：1，而主题：消费组中的消费者也是=n：1。此时消费者线程就可以根据拉取到的不同主题的消息进行不同的逻辑处理。==

##### ②、`public void assign(Collection<TopicPartition> partitions)`

消费者可以直接订阅特定主题的特定分区,==此举将跳开`partition.assignment.strategy`的限制,分区与消费者的对应关系不具备自动再均衡功能（也就是消费者的增加减少，分区的负责消费者也将发生变化）==

三种不同的订阅方式代表着三种互斥的订阅状态，每一个`KafkaConsumer`只能够选择其中一种方法进行订阅,如果同时使用将会抛出异常。要注意调用这两个方法修改订阅分区或主题并不会立即同步到服务端，而是在调用`poll()`方法时进行同步到服务端(类似于NIO的`register`)。

### ==Ⅲ、拉取消息消费==

==**MQ的消息消费模式有两种：推模式和拉模式。推模式指服务端主动将消息推送给消费者，这种模式的实时性比较好，但是客户端消费者有可能被源源不断到达的消息压垮；而拉模式的实时性较差，但是客户端可以根据自身的处理能力控制拉取信息量。**而Kafka采用的是拉模式。==

```java
public ConsumerRecords<K, V> poll(long timeout)
```

`poll()`将会拉取该消费者订阅的主题中负责的分区的消息,`ConsumerRecords`对象中专门有一个成员变量`Map<TopicPartition, List<ConsumerRecord<K, V>>>`来区分某条消息属于哪个主题分区。其中timeout指拉取时的阻塞时间，在拉取时没有可用数据会发生阻塞。

#### 1、分区维度消费

```java
public List<ConsumerRecord<K, V>> records(TopicPartition partition) 
```

由上面所说的成员变量就可以知道有这种方法，传入partition就返回该分区相应的消息。

#### 2、主题维度消费

```java
public Iterable<ConsumerRecord<K, V>> records(String topic)
```

### Ⅳ、位移提交

#### 1、背景

在每次调用`poll()`方法时,其返回的是分区中没有被消费过的消息集。要做到这一点，Kafka服务端就必须维护==每一个消费者组已经消费过的**主题分区的**消息的位移==（因为对于消费者组来说，某一个主题分区中的消息该消费者组只会消费一次，注意这个维度）。当发生再均衡操作时，例如新增了消费者，这个新来的消费者无从得知所属的消费者组已经消费了其负责的分区多少消息，所以这个时候只能根据Kafka服务端持久化保存的 **消费者组+主题分区唯一标识的消费位移**来获取未被消费的消息集。

#### 2、存储机制

Kafka将消费者提交的消费位移存储到一个内部的主题`_consumer_offsets`中。（旧版客户端是存储在ZK里的,可以看出Kafka在极力摆脱ZK,听说新版本已经完全摆脱ZK了）

![](E:\Typora\MyNote\resources\Kafka\位移提交下标.png)

消费者每次提交的消费位移都是`position`而不是`lastConsumerOffset`。

#### 3、三种提交方式

首先讲讲位移提交的原理,稍微看了下消费者客户端源码。

每次调用`poll()`方法拉取消息之后,内部会将拉取到的最新消息offset+1放入一个叫做`TopicPartitionState`对象的`position`成员变量中（**这个对象存储着当前消费者对某一个主题分区的各种状态**）。==这个`position`即是消费者端维护的消费位移，此成员变量关系到每次`poll()`请求拉取消息的起始位置、seek的实现以及位移提交`position`的记录.==

* 拉取消息的起始位置

  要清楚一个概念提交消费位移给`_consumer_offsets`只是为了在某些极端情况比如说再均衡时,让新负责某分区的消费者知道该从哪个位移开始拉取数据而已。那如果我一直不提交消费位移，难道消费者每一次都会拉取同一条消息吗？显然是不可能的，所以消费者也维护着一个拉取过的消息的消费位移，而这就是`TopicPartitionState`对象的`position`，在每次发送fetchRequest时都会将该分区的`position`作为入参放到请求里,而服务端也会根据这个入参返回以`position`为起始的offset的消息。

* 位移提交

  在进行位移提交时,会根据`TopicPartitionState`对象的`position`作为消费位移进行提交

* seek的实现

  虽然下面才讲到seek，但是其实它的原理非常简单。` seek(TopicPartition partition, long offset)`方法内部就是根据传进来的partition获取其`TopicPartitionState`对象,然后对`postion`赋值`offset`,就完了。之后再进行`poll()`操作时就会返回以`seek.offset`为起始的消息,若此时再进行同步位移提交,那么就会以`seek.offset`也就是此时的`position`作为位移 提交,也就是会覆盖掉`_consumer_offsets`的原有值,此时对于该消费者组来说消息就已经回溯了

> 再闲的蛋疼就去看看这篇解析https://blog.csdn.net/liyiming2017/article/details/89187474?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0&spm=1001.2101.3001.4242
>
> 在debug源码过程中手动修改了`max.poll.records`影响到具体代码逻辑的值(从2->10),且再三确定没有发起fetchRequest,却发现代码中已经拿到了10条数据返回了。==也就是说`max.poll.records`并不影响 消费者每次的拉取请求从服务端拉取多少条数据，而是影响每次调用`poll()`方法时返回给调用者多少条数据==，这也就引申出了上面这篇博客的内容----数据预先拉取。
>
> <img src="E:\Typora\MyNote\resources\Kafka\数据预拉取.jpg" style="zoom:40%;" />
>
> 可以看到预先拉取的流程中，fetchRequest的IO与消息业务处理是并行执行的，这样就能够提升拉取的效率。之后再调用`poll()`的时候就只需要读取缓存就能直接返回消息。

##### ①、`commitSync(final Map<TopicPartition, OffsetAndMetadata> offsets)`

`commitSync()`即是同步提交,不填写参数时该方法将会==**根据之前`poll()`方法拉取消息的最大位移进行提交(也就是`position`)**==,只要没发生不可恢复错误,该方法就会一直阻塞消费者知道直到完成。而如果出现了不可恢复错误，也可捕获进行相应的处理。**其中offsets参数可不填,填了就是按分区粒度和自己设置的offset提交消费位移...(没想到这么重要的东西让程序员自己来管理)。**

###### ₁、优点

* 提交实时
* 如果是单线程poll单线程消费后同步提交，那么将是最低概率出现重复提交的提交方法（这种顺序消息丢失不可能出现）

###### ₂、缺点

* 如果真按照上面的方法来提交，性能极差
* 下面两种情况基于单线程poll多线程消费
  * 在使用无参的同步提交时，会出现一种问题就是提交了不属于消费线程的消费位移（也就是提交多了），从而导致消息丢失（消费线程还没消费完消息，突然宕机，重启时消费位移已经过去了，无法知道宕机前消费的消息，消息丢失）
  * 使用有参的同步提交时，出现异常，此时若代码有重试提交机制，那么重试提交就有可能覆盖掉其他消费线程的消费提交（也就是回溯了，提交少了），从而导致重复消费

##### ②、`commitAsync(final Map<TopicPartition, OffsetAndMetadata> offsets,OffsetCommitCallback callback)`

`commitAsync()`即是异步提交,在提交逻辑执行时消费线程不会受到阻塞。此方法同样支持开发者自定义提交offset，并且有一个callback参数，这个参数提供了一个提交完成的回调方法，可以在回调中做一下日志记录什么的。

###### ₁、优点

* 异步提交不阻塞消费线程，性能相比于同步提交要更高

###### ₂、缺点

* 使用有参的同步提交时，出现异常，此时若**回调线程代码**有重试提交机制，那**回调重试提交**就有可能覆盖掉消费线程的消费提交（也就是回溯了，提交少了），从而导致重复消费

##### ③、自动提交

默认消费位移提交方式是自动提交。自动提交的机制是定期提交，由参数`auto.commit.interval.ms`控制,默认5s。自动位移提交的逻辑在`poll()`中实现,在**==发送fetchRequest之前==**会先检查与上次提交是否已经间隔了5s,若是则进行位移提交。

###### ₁、优点

* 无需开发者维护消费位移的提交，方便

###### ₂、缺点

* 重复消费场景：消费线程消费完，但是与上一次提交的间隔时间还没有到达参数限定值，此时发生宕机，就出现重复消费
* 单线程poll多线程消费消息丢失场景：poll线程不断执行，然而消费线程还没有消费完消息，此时poll线程检查到间隔时间到达参数限定值自动提交了，服务器宕机，就会出现消息丢失

### Ⅴ、指定位移消费

#### 1、方法参数

```java
public void seek(TopicPartition partition, long offset)
```

`seek()`的作用就是修改`TopicPartitionState`的`position`值,从而影响消费位移的提交与每次消息拉取的起始位置。这个功能可以用在如消息回溯、处理 再均衡后消费者无法从`_consumer_offsets`中找到负责分区的消费位移情况。

#### 2、使用要点

1. 通过上面的原理再引申一下，`assign()`会在方法调用的时候新创建一个`TopicPartitionState`,因为此时已经能确定消费者要负责的分区;而`subscribe()`则会在`poll()`的时候动态分配分区,再新创建一个`TopicPartitionState`。而`position`的修改必须是基于这个状态对象的,换句话来说就是`seek()`调用时改分区的`TopicPartitionState`必须要存在了。所以每次调用`seek()`之前都要调用一次`assign()`或`poll()`,否则报错。

2. ```java
   public void seekToBeginning(Collection<TopicPartition> partitions);
   ```

   这个方法的作用是将`position`调回到分区日志的起始位置,一般是0。然而Kafka的日志会有一个清理旧数据的操作，所以起始位置会自然增加，所以不一定是0。

### Ⅵ、客户端实现

首先明确一个要点：`KafkaProducer`是线程安全的,而`KafkaConsumer`则是非线程安全的。所以`KafkaConsumer`方法的调用必须是单线程的，否则会抛出异常。

#### 1、线程封闭

这种实现方式就是每一条线程都作为一个消费者，创建`KafkaConsumer`并调用`poll()`消费消息。

优点：

1. 能保证分区消息的顺序消费

缺点：

1. 消费线程数量受制于分区数，之前说过如果消费者数量多于分区数，那将有部分消费线程无法分配到分区负责
2. 横向扩展能力较差，一个分区的消息最多只能由一条线程消费
3. 如果消费线程消费比较慢，迟迟不调用下一次poll，在Kafka中堆积的消息过多，Kafka就会删除部分日志造成数据丢失

#### 2、多线程消费同一个分区

这种实现方式是利用`assign()`,强行让多个消费者负责同一个分区的消息。每条线程都调用`poll()`从同一个分区中拉取消息进行消费.

优点：

1. 实现了多线程消费,提高了扩展性

缺点:

极度不推荐这种方式。

1. 知道`position`原理就能进一步推出,每个`KafkaConsumer`都保持着自己的`position`,那么怎么保证安全共享多条线程之间的`position`状态。所以就要在业务代码里自己维护多条线程拉取的消息`offset`,再调用`seek`去精确拉取才不会出错了。这就是其中一点，拉取位移的控制和位移提交的控制都将由用户自己负责。
2. 难以保证消费顺序性。

#### 3、单线程`poll`多线程消费

这是扩展性最强也最符合实际应用的一种。进程中创建一条Poll线程，该Poll线程不断的拉取消息，没拉取一次消息，就将这些消息提交给线程池，让线程池去进行业务处理。

![](E:\Typora\MyNote\resources\Kafka\单线程poll多线程消费.png)

优点：

1. 多线程处理消息，提高扩展性
2. 真正的业务逻辑由线程池中的线程执行，所以不存在消息在Kafka堆积的情况。

缺点：

1. 可能会出现线程池扔掉消息或抛出异常的情况（具体看抛弃策略的设置），不过可以在处理时将其放进死信队列
2. 消息消费的顺序行难以保证
3. 如何合理的位移提交是个难点。
   1. 如果自动提交,就会出现上面所说的[情况](#₂、缺点)
   2. 如果是手动提交,那就同样会出现上面的[情况](#₂、缺点)
   3. 可以用滑动窗口法提交位移